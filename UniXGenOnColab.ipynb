{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sLZqEKCHSINi"
   },
   "source": [
    "# UniXGen on Colab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1tFHkB1dUqJ5"
   },
   "source": [
    "### UniXGen Roadmap\n",
    "\n",
    "| Component                | UniXGen (Original Paper)                      | Colab Reproduction                                                                                                                           |\n",
    "|:------------------------:|:----------------------------------------------|:----------------------------------------------------------------------------------------------------------------------------------------------|\n",
    "| **Data**                 | MIMIC‚ÄëCXR‚ÄëJPG images + reports                 | ‚úîÔ∏è **Filtered metadata** (strict image‚Äìreport matching) with **view‚Äëcounts** & **unique‚Äëview summary**<br/>‚úîÔ∏è **Single‚Äëview** & **Multi‚Äëview** CSVs for ablation |\n",
    "| **Tokenizer**            | ByteLevelBPETokenizer (BBPE)                   | Unchanged                                                                                                                                     |\n",
    "| **Image Encoder**        | VQGAN                                           | Unchanged                                                                                                                                     |\n",
    "| **Text Encoder**         | Transformer‚Äëbased BBPE embedding               | Unchanged                                                                                                                                     |\n",
    "| **Fusion Module**        | Joint Transformer encoder block                | Unchanged                                                                                                                                     |\n",
    "| **Loss Function**        | Contrastive + autoregressive                   | Unchanged                                                                                                                                     |\n",
    "| **Decoder**              | Transformer decoder (report + image)           | Unchanged                                                                                                                                     |\n",
    "| **Training Framework**   | PyTorch Lightning                              | ‚úîÔ∏è **on_test_epoch_end** callback to compute BLEU automatically<br/>‚úîÔ∏è Test outputs saved as¬†`.pt`                                              |\n",
    "| **Generation**           | Autoregressive sampling                        | ‚úîÔ∏è **Top‚Äëp (=0.9) + temperature (=0.7)** sampling (configurable)<br/>‚úîÔ∏è¬†`--random_mode_order` flag (fixed vs. random ordering) for ablation        |\n",
    "| **Ablation Sweeper**     | ‚Äî                                              | ‚úîÔ∏è `unified_run_ablation.py`: grid sweep over `under_sample`, `max_img_num`, `target_count`                                                    |\n",
    "| **Token‚ÄëOrder Ablation** | ‚Äî                                              | ‚úîÔ∏è `unified_run.py` + `--random_mode_order` (`True` vs. `False`) via `setup_modes()`                                                           |\n",
    "| **Evaluation Metrics**   | BLEU (text), FID (image), 14‚Äëdisease AUROC (CheXpert)                       | ‚úîÔ∏è **BLEU**, **BERTScore** (P/R/F1),<br/>‚úîÔ∏è Per‚Äësample & summary CSV exports                           |\n",
    "| **Checkpoints**          | Pretrained VQGAN + UniXGen                     | ‚úîÔ∏è Load original Lightning CKPT for inference<br/>‚úîÔ∏è Fully configurable via CLI (e.g.¬†`--max_img_num`,¬†`--target_count`,¬†`--random_mode_order`) |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vvxXFP5-TFIJ"
   },
   "source": [
    "## Setup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PpzknQixO15T"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Github Repo Clone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/slyncrafty/DL4H-PRJ-Group.git UniXGen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r8v1teyuQPfM"
   },
   "source": [
    "## Project Location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kSJuRTP3YCGk"
   },
   "outputs": [],
   "source": [
    "PRJ_ROOT ='/content/drive/MyDrive/UniXGen' ## set it to correct drive location\n",
    "%cd {PRJ_ROOT}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Directory Setup & Download Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir data\n",
    "!mkdir data/images     # Place MIMIC-CXR-JPG images\n",
    "!mkdir data/reports    # Place MIMIC-CXR Database reports\n",
    "!mkdir mimiccxr_vqgan  # Place Chest X-ray Tokenizer\n",
    "!mkdir ckpt            # Place .ckpt Model File \n",
    "!mkdir output          \n",
    "!mkdir output/decoded_images\n",
    "!mkdir output/decoded_reports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üîß Download MIMIC-CXR-JPG images & reports\n",
    "\n",
    "- You must be a credential user defined in PhysioNet to access the data.\n",
    "- Download chest X-rays from [MIMIC-CXR-JPG](https://physionet.org/content/mimic-cxr-jpg/2.0.0/) and Place images under **data/images/**\n",
    "- Download reports from [MIMIC-CXR Database](https://physionet.org/content/mimic-cxr/2.0.0/) and Place reports under **data/reports/**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üîß Download VQGAN Tokenizer\n",
    "\n",
    "- Download [Chest X-ray Tokenizer(VQGAN))](https://drive.google.com/drive/folders/1Ia_GqRrmZ8g6md02TC5_nkrGn6eUwVaG) and Place under **/mimiccxr_vqgan**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üîß Place model file under **/ckpt**\n",
    "\n",
    "- Download [Pre-updated UniXGen Model](https://drive.google.com/file/d/1LuZXq7DpQUV9cgWTLK6SRvlmSHu_a5E1/view?usp=drive_link) and Place model file under **/ckpt**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üîë Replace file: ./taming-transformers/taming/data/utils.py with [utils.py](https://drive.google.com/file/d/1NCO8hojet42JdrgX1vKV3uMPpCLBWDw8/view?usp=drive_link)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9ArAdYTQtNNK"
   },
   "source": [
    "## Installations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "savkeFkgy6uT"
   },
   "source": [
    "### Installing Required Packages / Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "Rk_TI3y_tO3S"
   },
   "outputs": [],
   "source": [
    "%cd {PRJ_ROOT}\n",
    "%pip install --upgrade pip\n",
    "%pip install -r requirements.txt\n",
    "%pip install pytorch-lightning==2.0.9 --force-reinstall\n",
    "%pip install --force-reinstall torch==2.0.1+cu118 torchvision==0.15.2+cu118 torchaudio==2.0.2+cu118 --index-url https://download.pytorch.org/whl/cu118\n",
    "%pip uninstall -y numpy\n",
    "%pip install numpy==1.24.4\n",
    "%pip uninstall -y jax jaxlib\n",
    "%pip install --upgrade jax==0.4.23 jaxlib==0.4.23"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "MyUbKSjEM2WK"
   },
   "outputs": [],
   "source": [
    "%cd {PRJ_ROOT}\n",
    "!git clone https://github.com/CompVis/taming-transformers.git\n",
    "%cd taming-transformers\n",
    "!pip install -e .\n",
    "%cd {PRJ_ROOT}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B9IlOpUsQMfe"
   },
   "source": [
    "### Check Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 46,
     "status": "ok",
     "timestamp": 1746461583449,
     "user": {
      "displayName": "adriane Yi",
      "userId": "01251788863007227054"
     },
     "user_tz": -60
    },
    "id": "pGRBYqM__lxn",
    "outputId": "8bd6d526-65a1-4a09-f73e-3ee392ee6244"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numpy 1.24.4\n",
      "scipy 1.10.1\n",
      "torch 2.7.0+cu126 cuda 12.6\n",
      "torchvision 0.15.2+cu118\n",
      "PL 2.0.9\n",
      "torchmetrics 1.7.1\n",
      "transformers 4.37.2\n"
     ]
    }
   ],
   "source": [
    "import numpy as np;        print(\"numpy\",     np.__version__)\n",
    "import scipy;              print(\"scipy\",     scipy.__version__)\n",
    "import torch;              print(\"torch\",     torch.__version__, \"cuda\", torch.version.cuda)\n",
    "import torchvision;        print(\"torchvision\", torchvision.__version__)\n",
    "import pytorch_lightning as pl; print(\"PL\",       pl.__version__)\n",
    "import torchmetrics;       print(\"torchmetrics\", torchmetrics.__version__)\n",
    "import transformers;       print(\"transformers\", transformers.__version__)\n",
    "import omegaconf;          print(\"omegaconf\", omegaconf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 503,
     "status": "ok",
     "timestamp": 1746461574339,
     "user": {
      "displayName": "adriane Yi",
      "userId": "01251788863007227054"
     },
     "user_tz": -60
    },
    "id": "-In-iMbCOAmv",
    "outputId": "eddc96f9-7eae-4751-efcb-6f93161446ca"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jax 0.4.23\n",
      "jaxlib 0.4.23\n"
     ]
    }
   ],
   "source": [
    "import jax;                print(\"jax\",       jax.__version__)\n",
    "import jaxlib;             print(\"jaxlib\",    jaxlib.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zjw_6arBhkPU"
   },
   "source": [
    "### File location check(Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 27133,
     "status": "ok",
     "timestamp": 1746097540354,
     "user": {
      "displayName": "Adriane Yi",
      "userId": "00971647119962514975"
     },
     "user_tz": -60
    },
    "id": "ygZdy7rWf8Lh",
    "outputId": "85a112de-cbea-4df8-e6aa-4dffe3e0191d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Checking paths and files...\n",
      "‚úÖ Checkpoint file found: ckpt/unixgen_lightning.ckpt\n",
      "‚úÖ Checkpoint loaded successfully, keys: ['pytorch-lightning_version', 'state_dict', 'callbacks', 'hparams_name', 'hyper_parameters', 'global_step', 'epoch', 'loops', 'legacy_pytorch-lightning_version']\n",
      "‚úÖ Tokenizer vocab and merges found.\n",
      "‚úÖ Tokenizer loaded and special tokens added.\n",
      "‚úÖ Test metadata file found: metadata/mimiccxr_test_filtered.csv\n",
      "‚úÖ Test metadata CSV loaded with 159 rows.\n",
      "‚úÖ Output directory exists: output\n",
      "\n",
      "üõ° Validation complete.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "from tokenizers import ByteLevelBPETokenizer\n",
    "\n",
    "### Adjust these paths to match your config\n",
    "ckpt_path = 'ckpt/unixgen_lightning.ckpt'\n",
    "vocab_path = 'BBPE_tokenizer/vocab.json'\n",
    "merges_path = 'BBPE_tokenizer/merges.txt'\n",
    "test_meta_file = 'metadata/mimiccxr_test_filtered.csv'\n",
    "output_dir = 'output'\n",
    "\n",
    "print(\"üîç Checking paths and files...\")\n",
    "\n",
    "# Check checkpoint\n",
    "if os.path.isfile(ckpt_path):\n",
    "    print(f\"‚úÖ Checkpoint file found: {ckpt_path}\")\n",
    "    try:\n",
    "        ckpt = torch.load(ckpt_path, map_location='cpu')\n",
    "        print(f\"‚úÖ Checkpoint loaded successfully, keys: {list(ckpt.keys())}\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Failed to load checkpoint: {e}\")\n",
    "else:\n",
    "    print(f\"‚ùå Checkpoint file NOT found: {ckpt_path}\")\n",
    "\n",
    "# Check tokenizer files\n",
    "if os.path.isfile(vocab_path) and os.path.isfile(merges_path):\n",
    "    print(f\"‚úÖ Tokenizer vocab and merges found.\")\n",
    "    try:\n",
    "        tokenizer = ByteLevelBPETokenizer(vocab_path, merges_path)\n",
    "        tokenizer.add_special_tokens([\"[PAD]\", \"[SOS]\", \"[EOS]\", \"[SEP]\", \"[MASK]\"])\n",
    "        print(\"‚úÖ Tokenizer loaded and special tokens added.\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Failed to load tokenizer: {e}\")\n",
    "else:\n",
    "    print(f\"‚ùå Missing vocab or merges file: {vocab_path}, {merges_path}\")\n",
    "\n",
    "# Check test metadata\n",
    "if os.path.isfile(test_meta_file):\n",
    "    print(f\"‚úÖ Test metadata file found: {test_meta_file}\")\n",
    "    try:\n",
    "        df = pd.read_csv(test_meta_file)\n",
    "        if df.empty:\n",
    "            print(\"‚ö†Ô∏è Test metadata CSV is EMPTY.\")\n",
    "        else:\n",
    "            print(f\"‚úÖ Test metadata CSV loaded with {len(df)} rows.\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Failed to load CSV: {e}\")\n",
    "else:\n",
    "    print(f\"‚ùå Test metadata file NOT found: {test_meta_file}\")\n",
    "\n",
    "# Check output directory\n",
    "if os.path.isdir(output_dir):\n",
    "    print(f\"‚úÖ Output directory exists: {output_dir}\")\n",
    "else:\n",
    "    try:\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "        print(f\"‚úÖ Output directory created: {output_dir}\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Failed to create output directory: {e}\")\n",
    "\n",
    "print(\"\\nüõ° Validation complete.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZqL4kcMrMPTJ"
   },
   "source": [
    "## Pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QZLrjRKNVoDr"
   },
   "source": [
    "#### Create Filtered metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 167,
     "status": "ok",
     "timestamp": 1746103142052,
     "user": {
      "displayName": "adriane Yi",
      "userId": "01251788863007227054"
     },
     "user_tz": -60
    },
    "id": "Z6hzn933soYB",
    "outputId": "e36822c6-5a76-4d64-a85f-3f617368e9f0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/drive/MyDrive/UniXGen\n",
      "/content/drive/MyDrive/UniXGen\n"
     ]
    }
   ],
   "source": [
    "%cd {PRJ_ROOT}\n",
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LrxY9B47wKnq"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Create a filtered metadata .csv file from image data available in the location.\n",
    "Add a column for unique view counts\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "from glob import glob\n",
    "import pandas as pd\n",
    "\n",
    "def generate_filtered_metadata_with_summary(\n",
    "    original_csv: str,\n",
    "    image_dir:      str,\n",
    "    detailed_output_csv: str,\n",
    "    summary_output_csv:  str,\n",
    "    missing_folder_report:   str = None,\n",
    "    missing_metadata_report: str = None\n",
    "):\n",
    "    \"\"\"\n",
    "    1) Read raw metadata (no headers) ‚Üí columns: dicom_id, subject_id, study_id, view, count\n",
    "    2) Find all study folders under `image_dir` that contain at least one .jpg\n",
    "    3) Report studies in metadata but no images, and vice versa (optional CSVs)\n",
    "    4) Write filtered detailed metadata (5 columns, no extras)\n",
    "    5) Write summary per-study CSV with total_images_in_study & unique_views_in_study\n",
    "    \"\"\"\n",
    "    # ‚Äî‚Äî‚Äî Load original metadata ‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî\n",
    "    with open(original_csv, 'r') as f:\n",
    "        first = f.readline()\n",
    "    sep = '\\t' if '\\t' in first else ','\n",
    "    cols = ['dicom_id','subject_id','study_id','view','count']\n",
    "    df = pd.read_csv(original_csv, sep=sep, header=None, names=cols, dtype=str)\n",
    "    meta_studies = set(df['study_id'].unique())\n",
    "    print(f\"‚úÖ Loaded original metadata: {len(df)} rows across {len(meta_studies)} studies.\")\n",
    "\n",
    "    # ‚Äî‚Äî‚Äî Scan image_dir for valid study folders ‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî\n",
    "    jpg_paths = glob(os.path.join(image_dir, '**', '*.jpg'), recursive=True)\n",
    "    img_studies = set()\n",
    "    for p in jpg_paths:\n",
    "        folder = os.path.basename(os.path.dirname(p))\n",
    "        if folder.lower().startswith('s'):  # e.g. s50051329\n",
    "            img_studies.add(folder[1:])\n",
    "    print(f\"‚úÖ Found {len(img_studies)} study folders with .jpg files in `{image_dir}`.\")\n",
    "\n",
    "    # ‚Äî‚Äî‚Äî Missing‚Äêin‚Äêfolder / Missing‚Äêin‚Äêmetadata reports ‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî\n",
    "    missing_folder   = sorted(meta_studies - img_studies)\n",
    "    missing_metadata = sorted(img_studies - meta_studies)\n",
    "    if missing_folder:\n",
    "        print(f\"‚ö†Ô∏è {len(missing_folder)} studies in metadata but no images.\")\n",
    "        if missing_folder_report:\n",
    "            pd.DataFrame(missing_folder, columns=['study_id'])\\\n",
    "              .to_csv(missing_folder_report, index=False)\n",
    "            print(f\"  ‚Üí Saved to {missing_folder_report}\")\n",
    "    if missing_metadata:\n",
    "        print(f\"‚ö†Ô∏è {len(missing_metadata)} image folders with no metadata.\")\n",
    "        if missing_metadata_report:\n",
    "            pd.DataFrame(missing_metadata, columns=['study_id'])\\\n",
    "              .to_csv(missing_metadata_report, index=False)\n",
    "            print(f\"  ‚Üí Saved to {missing_metadata_report}\")\n",
    "\n",
    "    # ‚Äî‚Äî‚Äî Filter metadata to only those studies with images ‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî\n",
    "    filtered = df[df['study_id'].isin(img_studies)].copy()\n",
    "    print(f\"‚úÖ Filtered metadata: {len(filtered)} rows across {filtered['study_id'].nunique()} studies.\")\n",
    "    filtered.to_csv(detailed_output_csv, index=False, header=False)\n",
    "    print(f\"  ‚Üí Wrote filtered detailed metadata to `{detailed_output_csv}`\")\n",
    "\n",
    "    # ‚Äî‚Äî‚Äî Build & write per-study summary ‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî\n",
    "    summary = (\n",
    "        filtered\n",
    "        .groupby('study_id')\n",
    "        .agg(\n",
    "            total_images_in_study=('dicom_id','count'),\n",
    "            unique_views_in_study=('view', pd.Series.nunique)\n",
    "        )\n",
    "        .reset_index()\n",
    "    )\n",
    "    summary.to_csv(summary_output_csv, index=False)\n",
    "    print(f\"‚úÖ Wrote summary metadata to `{summary_output_csv}`\")\n",
    "    print(\"üéØ All outputs and diagnostics complete.\\n\")\n",
    "\n",
    "\n",
    "def generate_experiment_csvs(\n",
    "    summary_csv:       str,\n",
    "    full_filtered_csv: str,\n",
    "    image_root_dir:    str,\n",
    "    output_dir:        str\n",
    "):\n",
    "    \"\"\"\n",
    "    1) Load summary metadata (must have columns: study_id, total_images_in_study, unique_views_in_study)\n",
    "    2) Load filtered detailed metadata (5 cols: dicom_id, subject_id, study_id, view, count)\n",
    "    3) Re-scan `image_root_dir` to enforce only studies with .jpg\n",
    "    4) Split into single-view (unique_views==1) vs multi-view (unique_views>=2)\n",
    "    5) Write single_view.csv & multi_view.csv (no headers)\n",
    "    \"\"\"\n",
    "    # ‚Äî‚Äî‚Äî Load inputs ‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî\n",
    "    summary_df = pd.read_csv(summary_csv, dtype={'study_id':str})\n",
    "    detail_df  = pd.read_csv(full_filtered_csv, header=None, dtype=str)\n",
    "    if detail_df.shape[1] != 5:\n",
    "        raise ValueError(f\"Expected 5 columns in `{full_filtered_csv}`, got {detail_df.shape[1]}\")\n",
    "    detail_df.columns = ['dicom_id','subject_id','study_id','view','count']\n",
    "\n",
    "    # ‚Äî‚Äî‚Äî Re-scan images to ensure only valid studies ‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî\n",
    "    jpgs = glob(os.path.join(image_root_dir, '**', '*.jpg'), recursive=True)\n",
    "    valid = set()\n",
    "    for p in jpgs:\n",
    "        fld = os.path.basename(os.path.dirname(p))\n",
    "        if fld.lower().startswith('s'):\n",
    "            valid.add(fld[1:])\n",
    "    summary_df = summary_df[summary_df['study_id'].isin(valid)]\n",
    "    detail_df  = detail_df[ detail_df['study_id'].isin(valid) ]\n",
    "\n",
    "    # ‚Äî‚Äî‚Äî Single-view split ‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî\n",
    "    single_ids = summary_df.query(\"unique_views_in_study == 1\")['study_id']\n",
    "    single_df  = detail_df[ detail_df['study_id'].isin(single_ids) ]\n",
    "    sv_path    = os.path.join(output_dir, 'single_view.csv')\n",
    "    single_df.to_csv(sv_path, index=False, header=False)\n",
    "    print(f\"‚úÖ Saved single-view CSV: `{sv_path}` ({len(single_df)} rows)\")\n",
    "\n",
    "    # ‚Äî‚Äî‚Äî Multi-view split ‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî\n",
    "    multi_ids = summary_df.query(\"unique_views_in_study >= 2\")['study_id']\n",
    "    multi_df  = detail_df[ detail_df['study_id'].isin(multi_ids) ]\n",
    "    mv_path   = os.path.join(output_dir, 'multi_view.csv')\n",
    "    multi_df.to_csv(mv_path, index=False, header=False)\n",
    "    print(f\"‚úÖ Saved multi-view CSV: `{mv_path}` ({len(multi_df)} rows)\")\n",
    "\n",
    "    print(\"üéØ Experiment CSV generation complete.\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 667,
     "status": "ok",
     "timestamp": 1746106251145,
     "user": {
      "displayName": "adriane Yi",
      "userId": "01251788863007227054"
     },
     "user_tz": -60
    },
    "id": "5Sz0r7uV3YE7",
    "outputId": "fea03fc7-5433-4484-d77c-91ca0e77d330"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Loaded original metadata: 4444 rows across 2799 studies.\n",
      "‚úÖ Found 427 study folders with .jpg files in `data/images`.\n",
      "‚ö†Ô∏è 2438 studies in metadata but no images.\n",
      "  ‚Üí Saved to metadata/missing_in_folder.csv\n",
      "‚ö†Ô∏è 66 image folders with no metadata.\n",
      "  ‚Üí Saved to metadata/missing_in_metadata.csv\n",
      "‚úÖ Filtered metadata: 526 rows across 361 studies.\n",
      "  ‚Üí Wrote filtered detailed metadata to `metadata/mimiccxr_test_filtered.csv`\n",
      "‚úÖ Wrote summary metadata to `metadata/mimiccxr_test_summary.csv`\n",
      "üéØ All outputs and diagnostics complete.\n",
      "\n",
      "‚úÖ Saved single-view CSV: `metadata/single_view.csv` (277 rows)\n",
      "‚úÖ Saved multi-view CSV: `metadata/multi_view.csv` (249 rows)\n",
      "üéØ Experiment CSV generation complete.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 1) Filter + summary\n",
    "generate_filtered_metadata_with_summary(\n",
    "    original_csv='metadata/mimiccxr_test_sub_final.csv',\n",
    "    image_dir='data/images',\n",
    "    detailed_output_csv='metadata/mimiccxr_test_filtered.csv',\n",
    "    summary_output_csv='metadata/mimiccxr_test_summary.csv',\n",
    "    missing_folder_report='metadata/missing_in_folder.csv',\n",
    "    missing_metadata_report='metadata/missing_in_metadata.csv',\n",
    ")\n",
    "\n",
    "# 2) Produce single-/multi-view experiment lists\n",
    "generate_experiment_csvs(\n",
    "    summary_csv='metadata/mimiccxr_test_summary.csv',\n",
    "    full_filtered_csv='metadata/mimiccxr_test_filtered.csv',\n",
    "    image_root_dir='data/images',\n",
    "    output_dir='metadata',\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "keTN4tPhxkid"
   },
   "source": [
    "### Fix ckpt version for compatibility(Optional)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PH0clJA1PaDU"
   },
   "source": [
    "Original ckpt file is trained using older library and to run, it is recommended to update. Below scripts help updating. We provided updated ckpt file. [unixgen_lightning.ckpt](https://drive.google.com/file/d/1LuZXq7DpQUV9cgWTLK6SRvlmSHu_a5E1/view?usp=drive_link) to be placed in /ckpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 11167,
     "status": "ok",
     "timestamp": 1746051375931,
     "user": {
      "displayName": "adriane Yi",
      "userId": "01251788863007227054"
     },
     "user_tz": -60
    },
    "id": "6QoEMxOpwxh_",
    "outputId": "0b929f9e-1395-4efb-8c17-d73fe8d14724"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîß  Loading  ckpt/unixgen.ckpt\n",
      "    ‚úî renamed transformerLM_unified.image_pos_emb.weights_0 ‚Üí transformerLM_unified.image_pos_emb.weights.0\n",
      "    ‚úî renamed transformerLM_unified.image_pos_emb.weights_1 ‚Üí transformerLM_unified.image_pos_emb.weights.1\n",
      "\n",
      "üìã Hyper-parameters stored in ckpt:\n",
      "{'img_vocab_size': 1024,\n",
      " 'max_img_num': 3,\n",
      " 'max_seq_len': 3334,\n",
      " 'num_img_tokens': 1035,\n",
      " 'target_count': 3}\n",
      "\n",
      "‚úÖ  Saved Lightning-compatible ckpt ‚Üí  ckpt/unixgen_lightning.ckpt\n"
     ]
    }
   ],
   "source": [
    "!python fix_unixgen_ckpt.py \\\n",
    "       --in_ckpt  ckpt/unixgen.ckpt \\\n",
    "       --out_ckpt ckpt/unixgen_lightning.ckpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10233,
     "status": "ok",
     "timestamp": 1746051413405,
     "user": {
      "displayName": "adriane Yi",
      "userId": "01251788863007227054"
     },
     "user_tz": -60
    },
    "id": "TKJJ17ZzvDaU",
    "outputId": "082e6916-082a-4fc7-e573-96958518a824"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r  0% 0/1 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/pytorch_lightning/utilities/migration/migration.py:203: PossibleUserWarning: You have multiple `ModelCheckpoint` callback states in this checkpoint, but we found state keys that would end up colliding with each other after an upgrade, which means we can't differentiate which of your checkpoint callbacks needs which states. At least one of your `ModelCheckpoint` callbacks will not be able to reload the state.\n",
      "  rank_zero_warn(\n",
      "100% 1/1 [00:01<00:00,  1.67s/it]\n"
     ]
    }
   ],
   "source": [
    "!python -m pytorch_lightning.utilities.upgrade_checkpoint ckpt/unixgen_lightning.ckpt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NlDuXIB8TMth"
   },
   "source": [
    "## Sanity Check"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GN92EfLnTMti"
   },
   "source": [
    "### Sanity Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1975,
     "status": "ok",
     "timestamp": 1746030504706,
     "user": {
      "displayName": "adriane Yi",
      "userId": "01251788863007227054"
     },
     "user_tz": -60
    },
    "id": "duNhVJLFTMtj",
    "outputId": "b8b29387-f5d7-4309-ac1d-2cfeb7f08beb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üì¶  Vocab size: 14526\n",
      "ID of [PAD] : 0\n",
      "ID of [SOS] : 1\n",
      "ID of [EOS] : 2\n",
      "ID of '.'   : 18\n",
      "\n",
      "üß™  First 40 IDs decode to:\n",
      " !\"#$%&'()*+,-./0123456789:;<=>?@ABC ‚Ä¶\n",
      "\n",
      "Round-trip ok? -> True\n"
     ]
    }
   ],
   "source": [
    "### Verify tokenizers are correctly loaded and aligning.\n",
    "import json, os\n",
    "from tokenizers import ByteLevelBPETokenizer\n",
    "from tokenizers.processors import BertProcessing\n",
    "\n",
    "VOCAB_PATH  = \"BBPE_tokenizer/vocab.json\"\n",
    "MERGE_PATH  = \"BBPE_tokenizer/merges.txt\"\n",
    "CKPT_PATH   = \"ckpt/unixgen.ckpt\"\n",
    "\n",
    "assert os.path.isfile(VOCAB_PATH) and os.path.isfile(MERGE_PATH), \"Tokenizer files missing!\"\n",
    "assert os.path.isfile(CKPT_PATH), \"Checkpoint file not found!\"\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ‚îÄ load tokenizer exactly as authors did ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "tok = ByteLevelBPETokenizer(VOCAB_PATH, MERGE_PATH)\n",
    "tok.add_special_tokens([\"[PAD]\", \"[SOS]\", \"[EOS]\", \"[SEP]\", \"[MASK]\"])\n",
    "tok._tokenizer.post_processor = BertProcessing(\n",
    "    (\"[EOS]\", tok.token_to_id(\"[EOS]\")),\n",
    "    (\"[SOS]\", tok.token_to_id(\"[SOS]\")),\n",
    ")\n",
    "\n",
    "print(\"üì¶  Vocab size:\", len(tok.get_vocab()))\n",
    "print(\"ID of [PAD] :\", tok.token_to_id(\"[PAD]\"))\n",
    "print(\"ID of [SOS] :\", tok.token_to_id(\"[SOS]\"))\n",
    "print(\"ID of [EOS] :\", tok.token_to_id(\"[EOS]\"))\n",
    "print(\"ID of '.'   :\", tok.token_to_id(\".\"))        # easy sanity anchor\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ‚îÄ quick decode check ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "sample_ids = list(range(40))     # first 40 token IDs\n",
    "decoded = tok.decode(sample_ids, skip_special_tokens=True)\n",
    "print(\"\\nüß™  First 40 IDs decode to:\\n\", decoded[:200], \"‚Ä¶\\n\")  # truncate print\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ‚îÄ quick encode / round-trip check ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "dummy = \"No pneumothorax. The heart is mildly enlarged.\"\n",
    "ids   = tok.encode(dummy).ids\n",
    "roundtrip = tok.decode(ids, skip_special_tokens=True)\n",
    "print(\"Round-trip ok? ->\", roundtrip == dummy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DAgGRClYTMtj"
   },
   "source": [
    "### Memory Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XFaF56KFTMtk"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.set_float32_matmul_precision('high')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 209,
     "status": "ok",
     "timestamp": 1746461279955,
     "user": {
      "displayName": "adriane Yi",
      "userId": "01251788863007227054"
     },
     "user_tz": -60
    },
    "id": "IXW8vv4mTMtk",
    "outputId": "954b38bf-e8c7-4851-ce89-dcb062575de9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon May  5 16:07:59 2025       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA L4                      Off |   00000000:00:03.0 Off |                    0 |\n",
      "| N/A   36C    P8             11W /   72W |       0MiB /  23034MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|  No running processes found                                                             |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kd_bfDSzTMtk"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.cuda.empty_cache()\n",
    "torch.cuda.ipc_collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 191
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 24,
     "status": "ok",
     "timestamp": 1746461283832,
     "user": {
      "displayName": "adriane Yi",
      "userId": "01251788863007227054"
     },
     "user_tz": -60
    },
    "id": "2sBZ5VtkTMtk",
    "outputId": "e98b5006-c647-4ccc-ee97-19f076d48fb7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory allocated: 0.0 GB\n",
      "Memory reserved: 0.0 GB\n"
     ]
    },
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'|===========================================================================|\\n|                  PyTorch CUDA memory summary, device ID 0                 |\\n|---------------------------------------------------------------------------|\\n|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\\n|===========================================================================|\\n|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\\n|---------------------------------------------------------------------------|\\n| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |\\n|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |\\n|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |\\n|---------------------------------------------------------------------------|\\n| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |\\n|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |\\n|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |\\n|---------------------------------------------------------------------------|\\n| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |\\n|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |\\n|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |\\n|---------------------------------------------------------------------------|\\n| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |\\n|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |\\n|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |\\n|---------------------------------------------------------------------------|\\n| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |\\n|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |\\n|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |\\n|---------------------------------------------------------------------------|\\n| Allocations           |       0    |       0    |       0    |       0    |\\n|       from large pool |       0    |       0    |       0    |       0    |\\n|       from small pool |       0    |       0    |       0    |       0    |\\n|---------------------------------------------------------------------------|\\n| Active allocs         |       0    |       0    |       0    |       0    |\\n|       from large pool |       0    |       0    |       0    |       0    |\\n|       from small pool |       0    |       0    |       0    |       0    |\\n|---------------------------------------------------------------------------|\\n| GPU reserved segments |       0    |       0    |       0    |       0    |\\n|       from large pool |       0    |       0    |       0    |       0    |\\n|       from small pool |       0    |       0    |       0    |       0    |\\n|---------------------------------------------------------------------------|\\n| Non-releasable allocs |       0    |       0    |       0    |       0    |\\n|       from large pool |       0    |       0    |       0    |       0    |\\n|       from small pool |       0    |       0    |       0    |       0    |\\n|---------------------------------------------------------------------------|\\n| Oversize allocations  |       0    |       0    |       0    |       0    |\\n|---------------------------------------------------------------------------|\\n| Oversize GPU segments |       0    |       0    |       0    |       0    |\\n|===========================================================================|\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "print(f\"Memory allocated: {torch.cuda.memory_allocated() / 1e9} GB\")\n",
    "print(f\"Memory reserved: {torch.cuda.memory_reserved() / 1e9} GB\")\n",
    "torch.cuda.memory_summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 109,
     "status": "ok",
     "timestamp": 1746461286024,
     "user": {
      "displayName": "adriane Yi",
      "userId": "01251788863007227054"
     },
     "user_tz": -60
    },
    "id": "EiLjjg7UTMtl",
    "outputId": "db3904bc-4aeb-4f98-efd7-8af91901ffc7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n"
     ]
    }
   ],
   "source": [
    "!nproc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vbOdDqOc3Br2"
   },
   "source": [
    "## Run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0ZBskHnA01cb"
   },
   "source": [
    "### For Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 5517958,
     "status": "ok",
     "timestamp": 1745840101956,
     "user": {
      "displayName": "adriane Yi",
      "userId": "01251788863007227054"
     },
     "user_tz": -60
    },
    "id": "Oug9hq3nuhmL",
    "outputId": "9c611295-a74c-4640-857c-576179ae929a"
   },
   "outputs": [],
   "source": [
    "# %cd {PRJ_ROOT}\n",
    "# !python unified_main.py --batch_size 10 --num_workers 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Jt00kOvx04ES"
   },
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "ypEcbE0RT-Bf"
   },
   "outputs": [],
   "source": [
    "#check stages\n",
    "%cd {PRJ_ROOT}\n",
    "!python unified_run.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SA2zJ00oynfe"
   },
   "source": [
    "### Ablation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "CZzhXLQF1Ztd"
   },
   "outputs": [],
   "source": [
    "%cd {PRJ_ROOT}\n",
    "!python unified_run_ablation.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0FAwJkgyRYlD"
   },
   "source": [
    "### Decode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "42Ns6qSYRnNk"
   },
   "source": [
    "#### Quick Preview output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 105,
     "status": "ok",
     "timestamp": 1746034642432,
     "user": {
      "displayName": "adriane Yi",
      "userId": "01251788863007227054"
     },
     "user_tz": -60
    },
    "id": "rGygf1oxiNyz",
    "outputId": "2d8c4ad8-ad35-4451-e363-ff97929a5e69"
   },
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "\n",
    "# Load the saved test outputs\n",
    "test_outputs = torch.load('output/<--Your--File--Name.pt-->', map_location='cpu')\n",
    "\n",
    "# Check how many\n",
    "print(f\"‚úÖ Loaded {len(test_outputs)} test outputs.\")\n",
    "\n",
    "# Let's preview first 3 reports\n",
    "for i in range(min(3, len(test_outputs))):\n",
    "    gt_tokens = test_outputs[i]['GT_text']\n",
    "    gen_tokens = test_outputs[i]['gen_text']\n",
    "\n",
    "    from tokenizers import ByteLevelBPETokenizer\n",
    "    tokenizer = ByteLevelBPETokenizer('BBPE_tokenizer/vocab.json', 'BBPE_tokenizer/merges.txt')\n",
    "    tokenizer.add_special_tokens([\"[PAD]\", \"[SOS]\", \"[EOS]\", \"[SEP]\", \"[MASK]\"])\n",
    "\n",
    "    gt_report = tokenizer.decode(gt_tokens[0].tolist(), skip_special_tokens=True)\n",
    "    gen_report = tokenizer.decode(gen_tokens[0].tolist(), skip_special_tokens=True)\n",
    "\n",
    "    print(f\"\\n=== Sample {i+1} ===\")\n",
    "    print(f\"Ground Truth:\\n{gt_report}\")\n",
    "    print(f\"Generated:\\n{gen_report}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mKvFL5AicSKs"
   },
   "source": [
    "#### Decode Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 230709,
     "status": "ok",
     "timestamp": 1746183027695,
     "user": {
      "displayName": "adriane Yi",
      "userId": "01251788863007227054"
     },
     "user_tz": -60
    },
    "id": "ngGfwwyGzFXz",
    "outputId": "b9fd532e-ce27-41ca-a053-c491b209f76f"
   },
   "outputs": [],
   "source": [
    "!python decode_cxr.py \\\n",
    "  --test_output_glob=\"./output/test_output_*.pt\" \\\n",
    "  --save_dir=\"./output/decoded_images/\" \\\n",
    "  --vqgan_model_path=\"./mimiccxr_vqgan/last.ckpt\" \\\n",
    "  --vqgan_config_path=\"./mimiccxr_vqgan/2021-12-17T08-58-54-project.yaml\" \\\n",
    "  --img_save=True \\\n",
    "  --preview=True\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wnUXhBEqcQE7"
   },
   "source": [
    "#### Decode Reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 9947,
     "status": "ok",
     "timestamp": 1746399035959,
     "user": {
      "displayName": "adriane Yi",
      "userId": "01251788863007227054"
     },
     "user_tz": -60
    },
    "id": "kfWPCY9myaXC",
    "outputId": "be7d0a32-5341-4ce0-a0a7-999913acffe7"
   },
   "outputs": [],
   "source": [
    "!python decode_report.py \\\n",
    "    --test_output_dir ./output \\\n",
    "    --tokenizer_dir BBPE_tokenizer \\\n",
    "    --save_csv \\\n",
    "    --save_dir ./output/decoded_reports\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9zEs-lnIRnhu"
   },
   "source": [
    "### Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "572dk-MogG6S"
   },
   "source": [
    "#### FID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 32756,
     "status": "ok",
     "timestamp": 1746183102189,
     "user": {
      "displayName": "adriane Yi",
      "userId": "01251788863007227054"
     },
     "user_tz": -60
    },
    "id": "hskM9wndnhcJ",
    "outputId": "c0c42df4-5864-4a8b-828e-3003d78203c1"
   },
   "outputs": [],
   "source": [
    "!python fid.py --gt_path ./output/decoded_images \\\n",
    "              --batch-size 32 --dims 1024 --num-workers 8\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cZ0Ca6UmLpNA"
   },
   "source": [
    "#### BLEU / BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 117,
     "status": "ok",
     "timestamp": 1746452730693,
     "user": {
      "displayName": "adriane Yi",
      "userId": "01251788863007227054"
     },
     "user_tz": -60
    },
    "id": "uE7m96KeBjBs",
    "outputId": "2c9677f7-5448-4f2b-fe5b-fed17291b16c"
   },
   "outputs": [],
   "source": [
    "!python evaluate_outputs.py \\\n",
    "    --decoded_glob \"./output/decoded_reports/*_GT_vs_GEN.csv\" \\\n",
    "    --output_csv \"./output/eval_summary.csv\""
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "Zjw_6arBhkPU",
    "ZqL4kcMrMPTJ",
    "keTN4tPhxkid",
    "NlDuXIB8TMth",
    "GN92EfLnTMti",
    "0ZBskHnA01cb",
    "42Ns6qSYRnNk"
   ],
   "gpuType": "L4",
   "machine_shape": "hm",
   "provenance": [
    {
     "file_id": "1rJHQJAnHQXpNLaREjCp-HCqwHnMxnQYC",
     "timestamp": 1746464264210
    },
    {
     "file_id": "1eC-K00N04LpKOXdl2YhcJRdqKSRgx3aP",
     "timestamp": 1745824461898
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
